# name: Full spikeinterface tests codecov

# on: workflow_dispatch

# env:
#   KACHERY_CLOUD_CLIENT_ID: ${{ secrets.KACHERY_CLOUD_CLIENT_ID }}
#   KACHERY_CLOUD_PRIVATE_KEY: ${{ secrets.KACHERY_CLOUD_PRIVATE_KEY }}

# jobs:
#   build-and-test:
#     name: Codecov
#     runs-on: "ubuntu-latest"
#     steps:
#       - uses: actions/checkout@v2
#       - uses: actions/setup-python@v4
#         with:
#           python-version: '3.9'
#       - name: Get current year-month
#         id: date
#         run: echo "date=$(date +'%Y-%m')" >> $GITHUB_OUTPUT
#       - uses: actions/cache@v3
#         id: cache-venv
#         with:
#           path: ~/test_env
#           key: ${{ runner.os }}-venv-${{ hashFiles('**/pyproject.toml') }}-${{ steps.date.outputs.date }}
#       - name: Python version
#         run: |
#           python --version
#       - name: Install dependencies
#         run: |
#           sudo apt update
#           # this is for datalad and download testing datasets
#           sudo apt install git 
#           # needed for correct operation of git/git-annex/DataLad
#           git config --global user.email "CI@example.com"
#           git config --global user.name "CI Almighty"
#           # this is for spyking circus
#           # sudo apt install mpich libmpich-dev
#           # create an environement (better for caching)
#           python -m venv ~/test_env
#           source ~/test_env/bin/activate
#           python -m pip install --upgrade pip
#           pip install setuptools wheel twine
#           ## clean some cache to avoid using old cache
#           pip cache remove numpy
#           pip cache remove hdbscan
#           pip cache remove numba
#           # herdingspikes need numpy to installed first, this numpy pre install will be removed when HS remove from testing
#           pip install numpy==1.22
#           pip install -e .[test,extractors,full]
#       - name: git-annex install
#         run: |
#           wget https://downloads.kitenet.net/git-annex/linux/current/git-annex-standalone-amd64.tar.gz
#           tar xvzf git-annex-standalone-amd64.tar.gz
#           echo "$(pwd)/git-annex.linux" >> $GITHUB_PATH
#       - name: git-annex version
#         run: |
#           git-annex version
#       - name: pip list
#         run: |
#           source ~/test_env/bin/activate
#           pip list
#       - name: Get ephy_testing_data current head hash
#         # the key depend on the last comit repo https://gin.g-node.org/NeuralEnsemble/ephy_testing_data.git
#         id: vars
#         run: |
#           echo "HASH_EPHY_DATASET=$(git ls-remote https://gin.g-node.org/NeuralEnsemble/ephy_testing_data.git HEAD | cut -f1)" >> $GITHUB_OUTPUT
#       - uses: actions/cache@v3
#         id: cache-datasets
#         env:
#           # the key depend on the last comit repo https://gin.g-node.org/NeuralEnsemble/ephy_testing_data.git
#           HASH_EPHY_DATASET: git ls-remote https://gin.g-node.org/NeuralEnsemble/ephy_testing_data.git HEAD | cut -f1
#         with:
#           path: ~/spikeinterface_datasets
#           key: ${{ runner.os }}-datasets-${{ steps.vars.outputs.HASH_EPHY_DATASET }}
#           restore-keys: |
#             ${{ runner.os }}-datasets
#       - name: run tests
#         run: |
#           source ~/test_env/bin/activate
#           pytest --cov=./ --cov-report xml:./coverage.xml
#       - uses: codecov/codecov-action@v3
#         with:
#           token: ${{ secrets.CODECOV_TOKEN }}
#           fail_ci_if_error: true
#           file: ./coverage.xml
#           flags: unittests
